#+TITLE: mrcal 3.0 release notes
#+OPTIONS: toc:nil

* New in mrcal 3.0

cross-reprojection

mrcal.drt_ref_refperturbed__dbpacked()
mrcal.compose_rt_tinyrt0_gradientrt0()
mrcal.compose_rt_tinyrt1_gradientrt1
compose_r_tinyr1_gradientr1

75893eea: Added initialy EARLY version of mrcal-show-stereo-pair-diff

* Migration notes 2.4 -> 3.0

* todo
- add notes about the triangulated-points merge

- new observed_pixel_uncertainty
  - apply sqrt() factor. Documented in 68789474. git grep -n
    observed_pixel_uncertainty ..
  - Does too little data give smaller residuals? It should. Is this reflected in
    the sqrt() factor?


** triangulated features merge
*** =git grep -n Noutliers= Noutliers has change meaning: it's now =Nmeasurements_outliers=

   #+begin_src diff
   diff --git a/doc/c-api.org b/doc/c-api.org
   index 7d3c8939..2ae7d9d5 100644
   --- a/doc/c-api.org
   +++ b/doc/c-api.org
        /* The RMS error of the optimized fit at the optimum. Generally the residual */
        /* vector x contains error values for each element of q, so N observed pixels */
        /* produce 2N measurements: len(x) = 2*N. And the RMS error is */
        /*   sqrt( norm2(x) / N ) */
        double rms_reproj_error__pixels;

   -    /* How many pixel observations were thrown out as outliers. Each pixel */
   -    /* observation produces two measurements. Note that this INCLUDES any */
   -    /* outliers that were passed-in at the start */
   +    /* How many measurements were thrown out as outliers. Each pixel */
   +    /* observation of a chessboard point produces two measurements (x,y). */
   +    /* Note: this INCLUDES any outliers that were passed-in at the start */
        int Noutliers;
    } mrcal_stats_t;


   --- a/mrcal-calibrate-cameras
   +++ b/mrcal-calibrate-cameras
   @@ -745,13 +745,13 @@ Npoints_chessboard = args.object_width_n*args.object_height_n*Nobservations
    residuals = \
        stats['x'][:Npoints_chessboard*2]. \
        reshape(Nobservations, args.object_height_n, args.object_width_n, 2)
    worst_point_err = np.sqrt(np.max(nps.norm2( nps.clump(residuals, n=3) )))
    report += f"Worst residual (by measurement): {worst_point_err:.01f} pixels\n"
    if not args.skip_outlier_rejection:
   -    report += "Noutliers: {} out of {} total points: {:.01f}% of the data\n". \
   +    report += "Noutliers: {} out of {} total measurements: {:.01f}% of the data\n". \
            format(stats['Noutliers'],
                   args.object_height_n*args.object_width_n*len(observations),
                   100.0 * stats['Noutliers'] / (args.object_height_n*args.object_width_n*len(observations)))
    if calobject_warp is not None:
        report += f"calobject_warp = {calobject_warp}\n"
 
   #+end_src

*** divergent-rays-are outlier logic is weird
I declare and outlier on the first pass. That pass is for getting the threshold

** patches deferred for next release

#+begin_src diff
diff --git a/mrcal-show-projection-diff b/mrcal-show-projection-diff
index 572d701..6cb48dc 100755
--- a/mrcal-show-projection-diff
+++ b/mrcal-show-projection-diff
@@ -503,3 +503,7 @@ if not args.intrinsics_only and args.radius != 0 and \
 
 if args.hardcopy is None:
     plot.wait()
+
+
+# should --unset key be the default? And for the uncertainty plot?
+
diff --git a/mrcal-show-residuals-board-observation b/mrcal-show-residuals-board-observation
index 76ce4db..b8c17eb 100755
--- a/mrcal-show-residuals-board-observation
+++ b/mrcal-show-residuals-board-observation
@@ -365,3 +365,8 @@ The optimization inputs are available in the optimization_inputs dict
 for i in range(Nplots):
     os.waitpid(pids[i], 0)
 sys.exit()
+
+
+
+
+### add auto-vector-scale
diff --git a/stereo.c b/stereo.c
index e03f3c2..5309575 100644
--- a/stereo.c
+++ b/stereo.c
@@ -568,3 +568,195 @@ bool mrcal_rectification_maps(// output
 
     return true;
 }
+
+#if 0
+void
+stereo_unproject(// output
+                 double* p, // (x,y,z) in aligned0 coords
+                 // input
+                 int i, int j, uint16_t disparity,
+                 const double* latlon_fxycxy,
+                 double baseline)
+{
+    // mrcal.stereo_range() and mrcal.unproject_latlon() has the docs for this
+    // function. This is a superset of stereo_range()
+
+
+    double fx = latlon_fxycxy[0];
+    double fy = latlon_fxycxy[1];
+    double cx = latlon_fxycxy[2];
+    double cy = latlon_fxycxy[3];
+
+    double fx_recip = 1. / fx;
+    double fy_recip = 1. / fy;
+
+    double lat = ((double)i - cx) * fx_recip;
+    double lon = ((double)j - cy) * fy_recip;
+
+    double clon,slon,clat,slat;
+    sincos(lat, &slat, &clat);
+    sincos(lon, &slon, &clon);
+
+    p[0] = slat;
+    p[1] = clat * slon;
+    p[2] = clat * clon;
+
+
+    double disparity_rad = (double)disparity * fx_recip / 16.;
+
+    double tandisp = tan(disparity_rad);
+
+    // cos(az - disparity_rad) / sdisp = (clat cdisp + slat sdisp) / sdisp =
+    // = clat / tandisp + slat
+    double r = baseline * (clat / tandisp + slat);
+    p[0] *= r;
+    p[1] *= r;
+    p[2] *= r;
+}
+
+double
+stereo_range( int i, uint16_t disparity,
+              int stereo_disp_shift,
+              const double* latlon_fxycxy,
+              double baseline)
+{
+    // mrcal.stereo_range() and mrcal.unproject_latlon() has the docs for this
+    // function. This is a subset of stereo_unproject()
+    if(disparity == 0)
+        return INFINITY;
+
+    double fx = latlon_fxycxy[0];
+    double cx = latlon_fxycxy[2];
+
+    double fx_recip = 1. / fx;
+
+    double lat = ((double)i - cx) * fx_recip;
+
+    double clat,slat;
+    sincos(lat, &slat, &clat);
+
+    double disparity_rad = (double)disparity * fx_recip / (double)(1 << stereo_disp_shift);
+
+    double tandisp = tan(disparity_rad);
+
+    // cos(az - disparity_rad) / sdisp = (clat cdisp + slat sdisp) / sdisp =
+    // = clat / tandisp + slat
+    return baseline * (clat / tandisp + slat);
+}
+
+void apply_disparity_diagnostic_map( // output
+                                     muse_image_bgr_t* diag,
+                                     // input
+                                     const muse_image_uint16_t* disparity,
+                                     int stereo_level,
+                                     int stereo_disp_shift)
+{
+    // I map disparities to colors. I care about ranges, so I simulate the range
+    // calculations by operating on 1/disparity. This only kinda works: the
+    // range scale factor varies across the image. I use gnuplot's colormapping
+    // structure. A palette can be designed and visualized with gnuplot. I'm
+    // using this:
+    //
+    //    set palette defined ( 0 "#0000ff", 0.05 "#00ffff", 0.1 "#00ff00", 0.5 "#ffff00", 1 "#ff0000" )
+    //    test palette
+    //
+    // This defines a linear interpolation. "test palette" visualizes it. Use
+    // that tool if modifying this
+    typedef struct
+    {
+        float q;
+        unsigned char r,g,b;
+    } control_point_t;
+    // ASSUMED that I'm in order of increasing q
+    const control_point_t cp[] =
+        { { 0.00f, 0,   0,   255 },
+          { 0.05f, 0,   255, 255 },
+          { 0.10f, 0,   255, 0 },
+          { 0.50f, 255, 255, 0 },
+          { 1.00f, 255, 0,   0 } };
+    const int Ncp = sizeof(cp) / sizeof(cp[0]);
+
+    // Value proportional to the "range" corresponding to the maximum color.
+    // Tweak as needed
+    const float qmax = 1e0f;
+
+    // This thing can run faster if everything is dense. So I enforce that
+    assert(diag       ->stride == sizeof(bgr_t)*   diag       ->cols);
+    assert(disparity->stride == sizeof(uint16_t)*disparity->cols);
+    assert(diag->rows == disparity->rows);
+    assert(diag->cols == disparity->cols);
+
+    bgr_t*    dst = (bgr_t   *)diag       ->data;
+    uint16_t* src = (uint16_t*)disparity->data;
+
+    float s = (float)(1U << stereo_disp_shift);
+    for(int i=0; i<diag->rows*diag->cols; i++)
+    {
+        if (*src == 0 )
+        {
+            // infinity. Black. Maybe it should be red? Black looks less scary
+            *dst = (bgr_t) {};
+        }
+        else if( *src > MUSE_STEREO_MAX_DISP)
+        {
+            // invalid stereo. Black
+            *dst = (bgr_t) {};
+        }
+        else
+        {
+            // valid disparity. Apply the color map
+            float q = s / (float)( (*src) << stereo_level );
+            q /= qmax;
+            // q is now in [0,1]
+            if( q <= 0.f)
+            {
+                *dst = (bgr_t) {.bgr = {cp[0].b,
+                                        cp[0].g,
+                                        cp[0].r}};
+
+            }
+            else if( q >= 1.f)
+            {
+                *dst = (bgr_t) {.bgr = {cp[Ncp-1].b,
+                                        cp[Ncp-1].g,
+                                        cp[Ncp-1].r}};
+            }
+            else
+            {
+                for( int i=1; i<Ncp; i++)
+                {
+                    // Are we in the linear segment [i-1,i] ? If so, do the
+                    // thing. If not, look for the next segment. I already
+                    // checked the bounds, so this if() will always trigger at
+                    // some point
+                    if( q <= cp[i].q)
+                    {
+                        q -= cp[i-1].q;
+                        q /= (cp[i].q - cp[i-1].q);
+
+                        // q is now in [0,1]
+                        float r = cp[i-1].r*(1-q) + cp[i].r*q;
+                        if(     r <= 0.f)   dst->bgr[2] = 0;
+                        else if(r >= 255.f) dst->bgr[2] = 255;
+                        else                dst->bgr[2] = (uint8_t)roundf(r);
+
+                        float g = cp[i-1].g*(1-q) + cp[i].g*q;
+                        if(     g <= 0.f)   dst->bgr[1] = 0;
+                        else if(g >= 255.f) dst->bgr[1] = 255;
+                        else                dst->bgr[1] = (uint8_t)roundf(g);
+
+                        float b = cp[i-1].b*(1-q) + cp[i].b*q;
+                        if(     b <= 0.f)   dst->bgr[0] = 0;
+                        else if(b >= 255.f) dst->bgr[0] = 255;
+                        else                dst->bgr[0] = (uint8_t)roundf(b);
+                        break;
+                    }
+                }
+            };
+        }
+
+        src++;
+        dst++;
+    }
+}
+#endif
#+end_src

** _propagate_calibration_uncertainty() needs to be exported in the API
** I should check the camera extrinsics uncertainty
If the camera geometry is very uncertain, the calibration isn't successful; even
if the variance in the other state variables compensates for these perfectly.
The _propagate_calibration_uncertainty() function can easily do this. I should
rename it. And I should expose it as part of the API. This code works to detect
uncertain extrinsics for a camera pair:

#+begin_src python

model_filename = sys.argv[1]
m = mrcal.cameramodel(model_filename)
optimization_inputs = m.optimization_inputs()

istate_extrinsics0 = mrcal.state_index_extrinsics(0, **optimization_inputs)
Nstate_extrinsics  = mrcal.num_states_extrinsics(    **optimization_inputs)

Nstate = mrcal.num_states( **optimization_inputs)

if Nstate_extrinsics != 6:
    raise Exception(f"Unexpected {Nstate_extrinsics=}")

dF_db = np.zeros((Nstate_extrinsics, Nstate), dtype=float)
dF_db[:,istate_extrinsics0:istate_extrinsics0+Nstate_extrinsics] = \
    np.eye(Nstate_extrinsics)

Var_rt_cam_ref = \
    mrcal.model_analysis._propagate_calibration_uncertainty('covariance',
                                                            dF_db = dF_db,
                                                            observed_pixel_uncertainty = 1.,
                                                            optimization_inputs = optimization_inputs)

print(f"stdev(rt_cam_ref) = {np.sqrt(np.diag(Var_rt_cam_ref))}")

#+end_src

** uncertainty regression
The triangulated-features merge caused the uncertainty reporting to be a bit
different for some reason. I need to chase it down to see what happened. I'm
looking at

~/projects/mrcal.old/out0.cameramodel

This command is returning slightly different results before/after the merge:

~/projects/mrcal.old/mrcal-show-projection-uncertainty out0.cameramodel --cbmax 30

** uncertainty strongly affected by regularization weight
Computing the uncertainty of the results of stationary-calibration.py can
produce wildly different output if I tweak the regularization weight

** regularization scaling
I should aim for specific number of pixels instead of for some ratio. This will
probably break loading optimization_inputs from model files: they'd need
reoptimization

** point range normalization
I removed it here: 0e727189. Do I want it back in some form? I do still require
point_min_range and point_max_range. Do I really need these?

** XyJax loaded in too many doc pages
I need it everywhere I use \xymatrix (currently uncertainty.org only). So that's
the only place I should use it. Loading it needlessly is slow

** Rename C files
mrcal-xxx.[ch] -> xxx.[ch]
Anything internal doesn't need to have a namespaced filename

** mrcal-convert-lensmodel
This needs to support points:
- search for indices_point_camintrinsics_camextrinsics
- solving without --sampled fails with points: no logic to do point culling

** mrcal-cull-corners should be able to cull board edges
Need new option like =--cull-board-rowscols L,T,R,B=

Can hack it on the commandline:

#+begin_src sh
R=1; < $C vnl-filter --sub 'ii() { if(filename != prev(filename)) { i=0; return i; } return ++i; }' -p .,'i=ii()' | vnl-filter -p .,\!i,'i=int(i/14)',j='i % 14' | vnl-filter -p filename,x,y,level="(i<$R || i>=14-$R || j<$R || j>=14-$R) ? \"-\" : level" > /tmp/corners-board-edge-cut$R.vnl
#+end_src

** mrcal-stereo should have an anti-aliasing filter
When I downsample. Just before =mrcal.transform_image()= it should

#+begin_src python
for i in range(len(images)):
    images[i] = cv2.GaussianBlur(images[i],
                                 ksize=(0,0), # auto-select
                                 # sigmaX = 2 ^ -pixels_per_deg,
                                 sigmaX = 2 )
#+end_src

** I should support more lens models
Being compatible with at least ROS would be nice. Their models are:

- =plumb_bob=: This is =LENSMODEL_OPENCV5=
- =rational_polynomial=: This is =LENSMODEL_OPENCV8=
- =equidistant=: mrcal does not support this today. It should. This is
  [[https://docs.opencv.org/3.4/db/d58/group__calib3d__fisheye.html][cv::fisheye]]

** More conversion functions
- Similarly I should have =mrcal-to-ros= and =mrcal-from-ros= to convert model
  files
  https://wiki.ros.org/camera_calibration_parsers
  https://github.com/ethz-asl/kalibr/wiki/supported-models
  https://github.com/ethz-asl/kalibr/wiki/Yaml-formats
  https://github.com/ethz-asl/kalibr/wiki/downloads

- Implement the write() functions for the different formats. For instance
  =write_kalibr()= should be finished
  
** compatibility camera model formats
Write tests. Read and confirm test/data/*.yaml. Each should be able to

#+begin_src python
m = mrcal.cameramodel('/tmp/tst3.yaml')
print(m)
#+end_src
** mrcal_drt_ref_refperturbed__dbpacked() currently is hardcoded to use the rrp formulation
Give it an argument to select the formulation. And rename the function. Or
something
* release checklist
These are notes to myself containing the steps needed to roll a new release

- docs: make sure all new python functions are described in python.org
- new [[file:versions.org][versions]]
- new [[file:news-2.2.org][news]]
- [[file:~/projects/mrcal/Makefile::PROJECT_NAME := mrcal][Makefile ABI version]]
- package build and upload
- versioned docs upload
- git tag
- move docs-default (symlink) on the server
